{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34e917e-5a47-4ac1-8efe-833960d6e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6f1aec-7768-4791-86dc-fcd7bd1e2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2f2096-a9e7-46a5-89be-55921f7d3454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8042</th>\n",
       "      <td>9041</td>\n",
       "      <td>1</td>\n",
       "      <td>Women look at porn too lmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11107</th>\n",
       "      <td>12436</td>\n",
       "      <td>1</td>\n",
       "      <td>You can get the internet in the Arctic, just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2860</td>\n",
       "      <td>1</td>\n",
       "      <td>What do you suggest to bring allies to the cause?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36293</th>\n",
       "      <td>39917</td>\n",
       "      <td>0</td>\n",
       "      <td>Uh, what?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27231</th>\n",
       "      <td>30098</td>\n",
       "      <td>0</td>\n",
       "      <td>Best place to start is to go back the source o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>23909</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't feel bad about eating humanely raised eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>23085</td>\n",
       "      <td>0</td>\n",
       "      <td>yes! also would note a lot of foods should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Context?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>10920</td>\n",
       "      <td>1</td>\n",
       "      <td>Second this. Few ideas:\\n1. Find some soyrizo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33437</th>\n",
       "      <td>36825</td>\n",
       "      <td>0</td>\n",
       "      <td>gonna nut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  subreddit  \\\n",
       "8042         9041          1   \n",
       "11107       12436          1   \n",
       "2531         2860          1   \n",
       "36293       39917          0   \n",
       "27231       30098          0   \n",
       "21458       23909          0   \n",
       "20685       23085          0   \n",
       "33             35          1   \n",
       "9726        10920          1   \n",
       "33437       36825          0   \n",
       "\n",
       "                                                    body  \n",
       "8042                         Women look at porn too lmao  \n",
       "11107  You can get the internet in the Arctic, just a...  \n",
       "2531   What do you suggest to bring allies to the cause?  \n",
       "36293                                          Uh, what?  \n",
       "27231  Best place to start is to go back the source o...  \n",
       "21458  Don't feel bad about eating humanely raised eg...  \n",
       "20685  yes! also would note a lot of foods should be ...  \n",
       "33                                              Context?  \n",
       "9726   Second this. Few ideas:\\n1. Find some soyrizo ...  \n",
       "33437                                          gonna nut  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e47839e-5725-4ad4-8004-911e9bd4a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385da573-18c1-40dd-8297-0e79a09c0ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>1</td>\n",
       "      <td>This is why I say people suck on a regular bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1</td>\n",
       "      <td>Costco sells a vegan source of EPA/DHA.\\n\\nAma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>1</td>\n",
       "      <td>Street by street block by block! Great pic. EC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33874</th>\n",
       "      <td>0</td>\n",
       "      <td>For frozen pizza, maybe, but for cheese off th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>Just took a glance at your comment history and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25725</th>\n",
       "      <td>0</td>\n",
       "      <td>His street corn salad recipe is so so good, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440</th>\n",
       "      <td>1</td>\n",
       "      <td>It’s called district eat play! It’s an arcade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10183</th>\n",
       "      <td>1</td>\n",
       "      <td>the fact that i’ve probably eaten a few bug le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14055</th>\n",
       "      <td>1</td>\n",
       "      <td>u gotta freeze them and squeeze them to get th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0</td>\n",
       "      <td>Aww geez, yes the girl I was with got sick and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit                                               body\n",
       "7705           1  This is why I say people suck on a regular bas...\n",
       "1264           1  Costco sells a vegan source of EPA/DHA.\\n\\nAma...\n",
       "17278          1  Street by street block by block! Great pic. EC...\n",
       "33874          0  For frozen pizza, maybe, but for cheese off th...\n",
       "118            1  Just took a glance at your comment history and...\n",
       "25725          0  His street corn salad recipe is so so good, I ...\n",
       "11440          1  It’s called district eat play! It’s an arcade ...\n",
       "10183          1  the fact that i’ve probably eaten a few bug le...\n",
       "14055          1  u gotta freeze them and squeeze them to get th...\n",
       "29672          0  Aww geez, yes the girl I was with got sick and..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de4baa3-0e7e-4303-b7c7-fb5402ba7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5133b916-7187-447c-96b6-8ca050b19c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a83d00c-cc36-4e1d-a446-d8225dcd8a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model\n",
      "Train score: 0.8376, Test score 0.7606\n",
      "Number of features: 27368\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "logr_model = make_pipeline(CountVectorizer(stop_words='english'),\n",
    "                           LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))\n",
    "\n",
    "cv_scores = cross_val_score(logr_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "logr_model.fit(X_train, y_train)\n",
    "y_pred = logr_model.predict(X_test)\n",
    "\n",
    "print('Logistic regression model')\n",
    "print('Train score: {}, Test score {}'.format(round(cv_scores.mean(), 4), round(roc_auc_score(y_test, y_pred), 4)))\n",
    "print('Number of features: {}'.format(len(logr_model.named_steps.countvectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c5bae72-4ed7-48e2-8550-8bb4b3f9ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive Bayes classifier\n",
      "Train score: 0.82645, Test score 0.75704\n",
      "Number of features: 27368\n"
     ]
    }
   ],
   "source": [
    "#MULTINOMAIL NAIVE BAYES CLASSIFIER\n",
    "mnb_model = make_pipeline(CountVectorizer(stop_words='english'), MultinomialNB())\n",
    "\n",
    "cv_scores = cross_val_score(mnb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "mnb_model.fit(X_train, y_train)\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "\n",
    "print('Multinomial naive Bayes classifier')\n",
    "print('Train score: {}, Test score {}'.format(round(cv_scores.mean(), 5), round(roc_auc_score(y_test, y_pred), 5)))\n",
    "print('Number of features: {}'.format(len(mnb_model.named_steps.countvectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b259b8ec-c942-4cfd-a202-afa5d851e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best params: {'cvec__max_df': 0.5, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'tfidf': TfidfTransformer(use_idf=False)}\n",
      "Train score: 0.8388, Test score 0.7575\n",
      "Number of features: 27368\n"
     ]
    }
   ],
   "source": [
    "#parameters for vectorizer\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', None),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = dict(\n",
    "    cvec__stop_words = [None, 'english'],\n",
    "    cvec__max_df = (0.5, 0.75, 1.0),\n",
    "    cvec__ngram_range = [(1, 1), (2, 2)],\n",
    "    tfidf = [None, TfidfTransformer(use_idf=True), TfidfTransformer(use_idf=False)]\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Best params: {}\".format(gs.best_params_))\n",
    "print('Train score: {}, Test score {}'.format(round(gs.best_score_, 4), round(gs.best_estimator_.score(X_test, y_test), 4)))\n",
    "print('Number of features: {}'.format(len(gs.best_estimator_.named_steps.cvec.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbadd39b-6571-45bf-a9c1-99c8cd655251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best params: {'cvec__stop_words': 'english', 'mnb__alpha': 0.7631578947368421, 'tfidf': TfidfTransformer()}\n",
      "Train score: 0.8342, Test score 0.7548\n",
      "Number of features: 27368\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameter for multinomial naive Bayes\n",
    "params = dict(\n",
    "    cvec__stop_words = ['english'],\n",
    "    tfidf = [TfidfTransformer(use_idf=True)],\n",
    "    mnb__alpha = np.linspace(0.1, 1.0, 20)\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Best params: {}\".format(gs.best_params_))\n",
    "print('Train score: {}, Test score {}'.format(round(gs.best_score_, 4), round(gs.best_estimator_.score(X_test, y_test), 4)))\n",
    "print('Number of features: {}'.format(len(gs.best_estimator_.named_steps.cvec.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbbfc44b-7656-422f-9d6d-6aee9d8f5403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict /r/vegetarian</th>\n",
       "      <th>predict /r/vegan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual /r/vegetarian</th>\n",
       "      <td>3520</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual /r/vegan</th>\n",
       "      <td>1042</td>\n",
       "      <td>3395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      predict /r/vegetarian  predict /r/vegan\n",
       "actual /r/vegetarian                   3520              1136\n",
       "actual /r/vegan                        1042              3395"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix LOGISTIC REGRESSION\n",
    "y_pred = logr_model.predict(X_test)\n",
    "\n",
    "conclusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                             columns=['predict /r/vegetarian', 'predict /r/vegan'],\n",
    "                             index=['actual /r/vegetarian', 'actual /r/vegan'])\n",
    "conclusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e709d0-2d1a-4f42-b30c-3374e9425c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7605\n",
      "Misclassification rate: 0.2395\n",
      "Precision: 0.7493\n",
      "Recall: 0.7652\n",
      "Specificity: 0.756\n"
     ]
    }
   ],
   "source": [
    "# Examine some classification metrics \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Accuracy: {}'.format(round((tp+tn)/(tp+fp+tn+fn),4)))\n",
    "print('Misclassification rate: {}'.format(round((fp+fn)/(tp+fp+tn+fn),4)))\n",
    "print('Precision: {}'.format(round(tp/(tp+fp),4)))\n",
    "print('Recall: {}'.format(round(tp/(tp+fn),4)))\n",
    "print('Specificity: {}'.format(round(tn/(tn+fp),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aa53d54-3d81-4fde-be8f-bd78c30d743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict /r/vegetarian</th>\n",
       "      <th>predict /r/vegan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual /r/vegetarian</th>\n",
       "      <td>3573</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual /r/vegan</th>\n",
       "      <td>1124</td>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      predict /r/vegetarian  predict /r/vegan\n",
       "actual /r/vegetarian                   3573              1083\n",
       "actual /r/vegan                        1124              3313"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix MULTINOMAIL NAIVE BAYES CLASSIFIER\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "\n",
    "conclusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                             columns=['predict /r/vegetarian', 'predict /r/vegan'],\n",
    "                             index=['actual /r/vegetarian', 'actual /r/vegan'])\n",
    "conclusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e121e2a9-de4d-4e84-9471-34ccb891f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7573\n",
      "Misclassification rate: 0.2427\n",
      "Precision: 0.7536\n",
      "Recall: 0.7467\n",
      "Specificity: 0.7674\n"
     ]
    }
   ],
   "source": [
    "# Examine some classification metrics \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Accuracy: {}'.format(round((tp+tn)/(tp+fp+tn+fn),4)))\n",
    "print('Misclassification rate: {}'.format(round((fp+fn)/(tp+fp+tn+fn),4)))\n",
    "print('Precision: {}'.format(round(tp/(tp+fp),4)))\n",
    "print('Recall: {}'.format(round(tp/(tp+fn),4)))\n",
    "print('Specificity: {}'.format(round(tn/(tn+fp),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce13534-0e93-498b-93d6-0daae8ca9e26",
   "metadata": {},
   "source": [
    "#### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcf32e-f4b5-4882-b574-cc37c0ec3bb0",
   "metadata": {},
   "source": [
    "- Our Logistic Regression model had an accuracy metric of 76.06% and naive Bayes classifier had an accuracy metric of 75.73%. Misclassification rate of Logistic Regression model is 23.95% and for naive Bayes classifier 24.27%. We definetly had a better perfomance with our Logistic Regression model. Nevertheless to get a better perfomance, I would optimize stop words, or I use a random forest classifier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
